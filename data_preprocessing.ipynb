{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3807423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lavanya/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['essay_set', 'essay', 'rater1_domain1', 'rater2_domain1', 'domain1_score', 'rubrics', 'prompt', 'content', 'organization', 'word_choice', 'sentence_fluency', 'conventions', '__index_level_0__'],\n",
      "        num_rows: 3583\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"llm-aes/asappp-1-2-original\")\n",
    "\n",
    "# View the dataset structure\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9c4b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['essay_set', 'essay', 'rater1_domain1', 'rater2_domain1', 'domain1_score', 'rubrics', 'prompt', 'content', 'organization', 'word_choice', 'sentence_fluency', 'conventions', '__index_level_0__']\n",
      "{'essay_set': 1, 'essay': \"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\", 'rater1_domain1': 4, 'rater2_domain1': 4, 'domain1_score': 8, 'rubrics': '•The grade seven and eight written responses are first drafts written by students in forty-five minutes in reaction to a prompt designed to elicit persuasive writing. Trained readers score these timed responses holistically, which means that they determine a score based on the overall impression most often gained from a single reading of the response.\\n•This rubric outlines a six-point scale. Each score point on that scale is described by an overall statement which captures the essence of the response. The elements of the response (elaboration, organization, fluency and audience awareness) that are typical for that score point are described below the overall statement. Individual responses may be stronger in one feature and weaker in another. In other words, the list of features at each score point, while helpful, cannot perfectly describe every response in a score-point category.\\n•A committee of expert readers uses this rubric as a guide to select anchor papers for each score point. Anchor papers are examples of actual student work. The committee prepares an anchor set composed of several papers at each score point. They deliberately select papers to show an appropriate range of writing skill for each score point and to represent the variety of approaches students take when addressing the writing prompt. Trained readers rely heavily on these anchor sets to guide their scoring.\\n•Errors in spelling, punctuation, grammar, and usage are not considered as part of the criteria for scoring writing samples. Also, papers receive a score based on the work the student did complete even if they seem to be unfinished. Because the writing sample is a timed response, it is generally assumed that these errors and omissions could have been corrected if the student had been given an opportunity to revise and edit. Readers are therefore trained to read through these errors when they score student papers.', 'prompt': 'More and more people use computers, but not everyone agrees that this benefits society. Those who support advances in technology believe that computers have a positive effect on people. They teach hand-eye coordination, give people the ability to learn about faraway places and people, and even allow people to talk online with other people. Others have different ideas. Some experts are concerned that people are spending too much time on their computers and less time exercising, enjoying nature, and interacting with family and friends. \\nWrite a letter to your local newspaper in which you state your opinion on the effects computers have on people. Persuade the readers to agree with you.', 'content': 4, 'organization': 3, 'word_choice': 3, 'sentence_fluency': 3, 'conventions': 3, '__index_level_0__': 0}\n"
     ]
    }
   ],
   "source": [
    "# Check column names in the training split\n",
    "print(dataset['train'].column_names)\n",
    "\n",
    "# View the first sample from the training split to get an idea of the columns\n",
    "print(dataset['train'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b27d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Clean function to remove unwanted characters\n",
    "def clean_text(text):\n",
    "    # Remove extra spaces and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Remove special characters (you can customize this as needed)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert text to lowercase (optional for uncased models)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply cleaning function to the dataset's text column\n",
    "dataset = dataset.map(lambda x: {'essay': clean_text(x['essay'])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ffad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'essay_set': 1, 'essay': 'dear local newspaper i think effects computers have on people are great learning skillsaffects because they give us time to chat with friendsnew people helps us learn about the globeastronomy and keeps us out of troble thing about dont you think so how would you feel if your teenager is always on the phone with friends do you ever time to chat with your friends or buisness partner about things well now  theres a new way to chat the computer theirs plenty of sites on the internet to do so organization1 organization2 caps1 facebook myspace ect just think now while your setting up meeting with your boss on the computer your teenager is having fun on the phone not rushing to get off cause you want to use it how did you learn about other countrysstates outside of yours well i have by computerinternet its a new way to learn about what going on in our time you might think your child spends a lot of time on the computer but ask them so question about the economy sea floor spreading or even about the date1s youll be surprise at how much heshe knows believe it or not the computer is much interesting then in class all day reading out of books if your child is home on your computer or at a local library its better than being out with friends being fresh or being perpressured to doing something they know isnt right you might not know where your child is caps2 forbidde in a hospital bed because of a driveby rather than your child on the computer learning chatting or just playing games safe and sound in your home or community place now i hope you have reached a point to understand and agree with me because computers can have great effects on you or child because it gives us time to chat with friendsnew people helps us learn about the globe and believe or not keeps us out of troble thank you for listening', 'rater1_domain1': 4, 'rater2_domain1': 4, 'domain1_score': 8, 'rubrics': '•The grade seven and eight written responses are first drafts written by students in forty-five minutes in reaction to a prompt designed to elicit persuasive writing. Trained readers score these timed responses holistically, which means that they determine a score based on the overall impression most often gained from a single reading of the response.\\n•This rubric outlines a six-point scale. Each score point on that scale is described by an overall statement which captures the essence of the response. The elements of the response (elaboration, organization, fluency and audience awareness) that are typical for that score point are described below the overall statement. Individual responses may be stronger in one feature and weaker in another. In other words, the list of features at each score point, while helpful, cannot perfectly describe every response in a score-point category.\\n•A committee of expert readers uses this rubric as a guide to select anchor papers for each score point. Anchor papers are examples of actual student work. The committee prepares an anchor set composed of several papers at each score point. They deliberately select papers to show an appropriate range of writing skill for each score point and to represent the variety of approaches students take when addressing the writing prompt. Trained readers rely heavily on these anchor sets to guide their scoring.\\n•Errors in spelling, punctuation, grammar, and usage are not considered as part of the criteria for scoring writing samples. Also, papers receive a score based on the work the student did complete even if they seem to be unfinished. Because the writing sample is a timed response, it is generally assumed that these errors and omissions could have been corrected if the student had been given an opportunity to revise and edit. Readers are therefore trained to read through these errors when they score student papers.', 'prompt': 'More and more people use computers, but not everyone agrees that this benefits society. Those who support advances in technology believe that computers have a positive effect on people. They teach hand-eye coordination, give people the ability to learn about faraway places and people, and even allow people to talk online with other people. Others have different ideas. Some experts are concerned that people are spending too much time on their computers and less time exercising, enjoying nature, and interacting with family and friends. \\nWrite a letter to your local newspaper in which you state your opinion on the effects computers have on people. Persuade the readers to agree with you.', 'content': 4, 'organization': 3, 'word_choice': 3, 'sentence_fluency': 3, 'conventions': 3, '__index_level_0__': 0, 'input_ids': [101, 6203, 2334, 3780, 1045, 2228, 3896, 7588, 2031, 2006, 2111, 2024, 2307, 4083, 4813, 10354, 25969, 2015, 2138, 2027, 2507, 2149, 2051, 2000, 11834, 2007, 2814, 2638, 2860, 2111, 7126, 2149, 4553, 2055, 1996, 7595, 14083, 4948, 16940, 1998, 7906, 2149, 2041, 1997, 19817, 16429, 2571, 2518, 2055, 2123, 2102, 2017, 2228, 2061, 2129, 2052, 2017, 2514, 2065, 2115, 10563, 2003, 2467, 2006, 1996, 3042, 2007, 2814, 2079, 2017, 2412, 2051, 2000, 11834, 2007, 2115, 2814, 2030, 20934, 2483, 2791, 4256, 2055, 2477, 2092, 2085, 2045, 2015, 1037, 2047, 2126, 2000, 11834, 1996, 3274, 17156, 7564, 1997, 4573, 2006, 1996, 4274, 2000, 2079, 2061, 3029, 2487, 3029, 2475, 9700, 2487, 9130, 24927, 14925, 2102, 2074, 2228, 2085, 2096, 2115, 4292, 2039, 3116, 2007, 2115, 5795, 2006, 1996, 3274, 2115, 10563, 2003, 2383, 4569, 2006, 1996, 3042, 2025, 8375, 2000, 2131, 2125, 3426, 2017, 2215, 2000, 2224, 2009, 2129, 2106, 2017, 4553, 2055, 2060, 2406, 4757, 12259, 2015, 2648, 1997, 6737, 2092, 1045, 2031, 2011, 3274, 18447, 11795, 3388, 2049, 1037, 2047, 2126, 2000, 4553, 2055, 2054, 2183, 2006, 1999, 2256, 2051, 2017, 2453, 2228, 2115, 2775, 15970, 1037, 2843, 1997, 2051, 2006, 1996, 3274, 2021, 3198, 2068, 2061, 3160, 2055, 1996, 4610, 2712, 2723, 9359, 2030, 2130, 2055, 1996, 3058, 2487, 2015, 2017, 3363, 2022, 4474, 2012, 2129, 2172, 2002, 4095, 2063, 4282, 2903, 2009, 2030, 2025, 1996, 3274, 2003, 2172, 5875, 2059, 1999, 2465, 2035, 2154, 3752, 2041, 1997, 2808, 2065, 2115, 2775, 2003, 2188, 2006, 2115, 3274, 2030, 2012, 1037, 2334, 3075, 2049, 2488, 2084, 2108, 2041, 2007, 2814, 2108, 4840, 2030, 2108, 2566, 20110, 12165, 2000, 2725, 2242, 2027, 2113, 3475, 2102, 2157, 2017, 2453, 2025, 2113, 2073, 2115, 2775, 2003, 9700, 2475, 27206, 3207, 1999, 1037, 2902, 2793, 2138, 1997, 1037, 3298, 3762, 2738, 2084, 2115, 2775, 2006, 1996, 3274, 4083, 22331, 2030, 2074, 2652, 2399, 3647, 1998, 2614, 1999, 2115, 2188, 2030, 2451, 2173, 2085, 1045, 3246, 2017, 2031, 2584, 1037, 2391, 2000, 3305, 1998, 5993, 2007, 2033, 2138, 7588, 2064, 2031, 2307, 3896, 2006, 2017, 2030, 2775, 2138, 2009, 3957, 2149, 2051, 2000, 11834, 2007, 2814, 2638, 2860, 2111, 7126, 2149, 4553, 2055, 1996, 7595, 1998, 2903, 2030, 2025, 7906, 2149, 2041, 1997, 19817, 16429, 2571, 4067, 2017, 2005, 5962, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load pre-trained BERT tokenizer (uncased version)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['essay'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Check tokenized data\n",
    "print(tokenized_datasets['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6fcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Extract the scores from the dataset\n",
    "labels = torch.tensor(dataset['train']['domain1_score'], dtype=torch.float32)\n",
    "\n",
    "# Step 2: Normalize using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "normalized_array = scaler.fit_transform(labels.unsqueeze(1).numpy())  # Convert to NumPy array and reshape\n",
    "\n",
    "# Step 3: Convert to flat list (1D)\n",
    "normalized_labels = normalized_array.flatten().tolist()\n",
    "\n",
    "# Step 4: Add normalized labels to dataset\n",
    "dataset['train'] = dataset['train'].add_column('normalized_score', normalized_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a4cbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the column if it already exists\n",
    "if 'normalized_score' in dataset['train'].column_names:\n",
    "    dataset['train'] = dataset['train'].remove_columns(['normalized_score'])\n",
    "\n",
    "# Now add it cleanly\n",
    "dataset['train'] = dataset['train'].add_column('normalized_score', normalized_labels)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da7df46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'essay_set': 1, 'essay': 'dear local newspaper i think effects computers have on people are great learning skillsaffects because they give us time to chat with friendsnew people helps us learn about the globeastronomy and keeps us out of troble thing about dont you think so how would you feel if your teenager is always on the phone with friends do you ever time to chat with your friends or buisness partner about things well now  theres a new way to chat the computer theirs plenty of sites on the internet to do so organization1 organization2 caps1 facebook myspace ect just think now while your setting up meeting with your boss on the computer your teenager is having fun on the phone not rushing to get off cause you want to use it how did you learn about other countrysstates outside of yours well i have by computerinternet its a new way to learn about what going on in our time you might think your child spends a lot of time on the computer but ask them so question about the economy sea floor spreading or even about the date1s youll be surprise at how much heshe knows believe it or not the computer is much interesting then in class all day reading out of books if your child is home on your computer or at a local library its better than being out with friends being fresh or being perpressured to doing something they know isnt right you might not know where your child is caps2 forbidde in a hospital bed because of a driveby rather than your child on the computer learning chatting or just playing games safe and sound in your home or community place now i hope you have reached a point to understand and agree with me because computers can have great effects on you or child because it gives us time to chat with friendsnew people helps us learn about the globe and believe or not keeps us out of troble thank you for listening', 'rater1_domain1': 4, 'rater2_domain1': 4, 'domain1_score': 8, 'rubrics': '•The grade seven and eight written responses are first drafts written by students in forty-five minutes in reaction to a prompt designed to elicit persuasive writing. Trained readers score these timed responses holistically, which means that they determine a score based on the overall impression most often gained from a single reading of the response.\\n•This rubric outlines a six-point scale. Each score point on that scale is described by an overall statement which captures the essence of the response. The elements of the response (elaboration, organization, fluency and audience awareness) that are typical for that score point are described below the overall statement. Individual responses may be stronger in one feature and weaker in another. In other words, the list of features at each score point, while helpful, cannot perfectly describe every response in a score-point category.\\n•A committee of expert readers uses this rubric as a guide to select anchor papers for each score point. Anchor papers are examples of actual student work. The committee prepares an anchor set composed of several papers at each score point. They deliberately select papers to show an appropriate range of writing skill for each score point and to represent the variety of approaches students take when addressing the writing prompt. Trained readers rely heavily on these anchor sets to guide their scoring.\\n•Errors in spelling, punctuation, grammar, and usage are not considered as part of the criteria for scoring writing samples. Also, papers receive a score based on the work the student did complete even if they seem to be unfinished. Because the writing sample is a timed response, it is generally assumed that these errors and omissions could have been corrected if the student had been given an opportunity to revise and edit. Readers are therefore trained to read through these errors when they score student papers.', 'prompt': 'More and more people use computers, but not everyone agrees that this benefits society. Those who support advances in technology believe that computers have a positive effect on people. They teach hand-eye coordination, give people the ability to learn about faraway places and people, and even allow people to talk online with other people. Others have different ideas. Some experts are concerned that people are spending too much time on their computers and less time exercising, enjoying nature, and interacting with family and friends. \\nWrite a letter to your local newspaper in which you state your opinion on the effects computers have on people. Persuade the readers to agree with you.', 'content': 4, 'organization': 3, 'word_choice': 3, 'sentence_fluency': 3, 'conventions': 3, '__index_level_0__': 0, 'normalized_score': 0.6363636255264282}\n"
     ]
    }
   ],
   "source": [
    "# Check the first few rows to ensure the column is added\n",
    "print(dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0605c810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2866\n",
      "Test size: 717\n"
     ]
    }
   ],
   "source": [
    "# Use the .train_test_split method from Hugging Face Datasets\n",
    "split_dataset = tokenized_datasets['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Access the train and test datasets\n",
    "train_dataset = split_dataset['train']\n",
    "test_dataset = split_dataset['test']\n",
    "\n",
    "# Step 1: Extract raw scores from both train and test splits\n",
    "train_scores = np.array(train_dataset['domain1_score']).reshape(-1, 1)\n",
    "test_scores = np.array(test_dataset['domain1_score']).reshape(-1, 1)\n",
    "\n",
    "# Step 2: Fit scaler on train only (standard practice)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_scores)\n",
    "\n",
    "# Step 3: Normalize both sets\n",
    "train_normalized = scaler.transform(train_scores).flatten().tolist()\n",
    "test_normalized = scaler.transform(test_scores).flatten().tolist()\n",
    "\n",
    "# Step 4: Add them back to datasets\n",
    "# Remove the column if it already exists\n",
    "if \"normalized_score\" in train_dataset.column_names:\n",
    "    train_dataset = train_dataset.remove_columns(\"normalized_score\")\n",
    "if \"normalized_score\" in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns(\"normalized_score\")\n",
    "\n",
    "# Add the new normalized score column\n",
    "train_dataset = train_dataset.add_column(\"normalized_score\", train_normalized)\n",
    "test_dataset = test_dataset.add_column(\"normalized_score\", test_normalized)\n",
    "\n",
    "\n",
    "# Check the sizes\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Test size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c424b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert Hugging Face columns to tensors\n",
    "train_data = TensorDataset(\n",
    "    torch.tensor(train_dataset['input_ids']),\n",
    "    torch.tensor(train_dataset['attention_mask']),\n",
    "    torch.tensor(train_dataset['normalized_score'], dtype=torch.float32)\n",
    ")\n",
    "\n",
    "test_data = TensorDataset(\n",
    "    torch.tensor(test_dataset['input_ids']),\n",
    "    torch.tensor(test_dataset['attention_mask']),\n",
    "    torch.tensor(test_dataset['normalized_score'], dtype=torch.float32)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65bef656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_dataset.csv and test_dataset.csv with normalized scores.\n"
     ]
    }
   ],
   "source": [
    "# Convert to pandas DataFrame\n",
    "train_df = train_dataset.to_pandas()\n",
    "test_df = test_dataset.to_pandas()\n",
    "\n",
    "# Save as CSV\n",
    "train_df.to_csv(\"train_dataset.csv\", index=False)\n",
    "test_df.to_csv(\"test_dataset.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved train_dataset.csv and test_dataset.csv with normalized scores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efdacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning the Bert + biLstm model to our data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "class BertBiLSTMRegressor(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-uncased', hidden_dim=128, num_layers=1, dropout=0.3):\n",
    "        super(BertBiLSTMRegressor, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.bert.config.hidden_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.regressor = nn.Linear(hidden_dim * 2, 1)  # *2 because of BiLSTM\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            sequence_output = outputs.last_hidden_state  # shape: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        lstm_output, _ = self.lstm(sequence_output)  # shape: (batch_size, seq_len, hidden_dim * 2)\n",
    "        pooled_output = torch.mean(lstm_output, dim=1)  # mean pooling across sequence length\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        score = self.regressor(pooled_output)  # shape: (batch_size, 1)\n",
    "        return score.squeeze(1)  # shape: (batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30ed8ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lavanya/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BertBiLSTMRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the test data and train data set into tesor type to give it to the model\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def create_dataloader(dataset, batch_size=8):\n",
    "    input_ids = torch.tensor(dataset['input_ids'])\n",
    "    attention_mask = torch.tensor(dataset['attention_mask'])\n",
    "    labels = torch.tensor(dataset['normalized_score'], dtype=torch.float)\n",
    "\n",
    "    data = TensorDataset(input_ids, attention_mask, labels)\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "train_loader = create_dataloader(train_dataset)\n",
    "test_loader = create_dataloader(test_dataset, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a02fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ed088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0473\n",
      "Epoch 2, Loss: 0.0150\n",
      "Epoch 3, Loss: 0.0125\n"
     ]
    }
   ],
   "source": [
    "# trainning the model\n",
    "def train(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "for epoch in range(3):  # You can adjust the number of epochs\n",
    "    avg_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "775d9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"bert_bilstm_essay_scorer.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a578704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertBiLSTMRegressor(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(768, 128, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (regressor): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved file\n",
    "model = BertBiLSTMRegressor()\n",
    "model.load_state_dict(torch.load(\"model/bert_bilstm_essay_scorer.pt\"))\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b047ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_essay(essay):\n",
    "    # Clean the essay\n",
    "    cleaned_essay = clean_text(essay)\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(cleaned_essay, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "    return inputs\n",
    "\n",
    "essay = \"\"\"\n",
    "In recent years, technology has dramatically transformed the way we communicate, learn, and work. The rapid development of the internet and digital devices has created new opportunities for people around the world to connect with one another. While this technological revolution has brought about many positive changes, it has also raised concerns about its potential negative effects on society.\n",
    "\n",
    "One of the most significant benefits of modern technology is its ability to facilitate communication. Social media platforms, video conferencing tools, and messaging apps have made it easier for people to stay in touch with friends, family, and colleagues, regardless of distance. These tools have been particularly important during the COVID-19 pandemic, when many individuals and businesses had to rely on virtual communication to continue functioning.\n",
    "\n",
    "Another major advantage of technology is its role in education. Online learning platforms and digital resources have made education more accessible to individuals who may not have had the opportunity to attend traditional schools. Students can now access courses and materials from top universities and educators, regardless of their location or financial situation. This has the potential to level the playing field and provide more people with the skills they need to succeed in the modern workforce.\n",
    "\n",
    "However, despite these advantages, there are several concerns associated with the rapid growth of technology. One of the most pressing issues is the potential for increased social isolation. As more people spend time interacting with others online, they may neglect face-to-face relationships, leading to feelings of loneliness and disconnection. Additionally, the overuse of technology can lead to addiction, as individuals may become overly reliant on their devices for entertainment, socialization, and work.\n",
    "\n",
    "Another concern is the impact of technology on privacy. With the rise of social media, online shopping, and data-driven advertising, personal information is being collected and shared more than ever before. This has raised concerns about the potential for misuse of personal data and the erosion of privacy rights. Many people are unaware of the extent to which their data is being collected, and there is a growing need for stronger regulations to protect individuals' privacy.\n",
    "\n",
    "In conclusion, while technology has brought about numerous benefits, it is important to recognize the potential downsides. As we continue to embrace new digital tools, we must be mindful of their impact on our social lives, privacy, and overall well-being. By finding a balance between the advantages and disadvantages of technology, we can ensure that it continues to serve humanity in a positive and meaningful way.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Preprocess the essay\n",
    "inputs = preprocess_essay(new_essay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2421f823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Essay Score: 4.311216354370117\n"
     ]
    }
   ],
   "source": [
    "# Ensure model is on the correct device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Preprocess the essay\n",
    "inputs = preprocess_essay(new_essay)\n",
    "\n",
    "# Move inputs to the same device as the model\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Predict the score\n",
    "with torch.no_grad():\n",
    "    predicted_score = model(inputs['input_ids'], inputs['attention_mask'])\n",
    "    predicted_score = predicted_score.item()  # Get the scalar value from tensor\n",
    "\n",
    "# Denormalize the predicted score\n",
    "predicted_score_denormalized = scaler.inverse_transform([[predicted_score]])[0][0]\n",
    "print(f\"Predicted Essay Score: {predicted_score_denormalized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a6696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
